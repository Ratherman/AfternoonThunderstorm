{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "arh2eUR8BoGk"
   },
   "source": [
    "# 臺北午後雷陣雨預報系統 V1.0\n",
    "\n",
    "###### 筆者: 中央大氣 109級 鄭中嘉\n",
    "###### 聯絡信箱: ratherman5796@gmail.com\n",
    "\n",
    "## 更新情況:\n",
    "* 2020/ 09/ 26 初版製成\n",
    "* ...\n",
    "* 2020/ 11/ 17 預計 V1.1 製成時間\n",
    "\n",
    "## 前言:\n",
    "當時修了周哲維老師的天氣與人工智慧時，老師提了這個有趣的題目出來，原本希望在畢業前能做出個成果，希望可以畫下一個完整的標點符號，結果...反正就到現在才有一個初版，而且這個還是未完待續的逗點，而非當初想像的句點，日後繼續更新!\n",
    "\n",
    "另外，下面有提到的一些 code 是真的寫得蠻簡陋的，但總之勉強還堪用。\n",
    "完整的 code 放在 Github 上，可以 clone 下來 run 看看。\n",
    "\n",
    "## 流程:\n",
    "1. 研究概述\n",
    "2. 資料取得\n",
    "3. 合併資料\n",
    "4. 機器學習\n",
    "5. 未來目標\n",
    "6. 參考連結"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P54qy0S8D4Lp"
   },
   "source": [
    "# **1. 研究概述**\n",
    "\n",
    "### **背景**\n",
    "午後雷陣雨在夏季的臺北算是一個常見的天氣型態，不過因為午後雷陣雨是個短時間內就會生成的天氣系統，所以天氣預報上並沒有辦法很準確的去預報中午過後會不會有午後雷陣雨發生。目前氣象局方面有的對案是利用 [大台北午後對流檢查表](https://watch.ncdr.nat.gov.tw/watch_ntp) 等機制做到預判，其機制是根據「模糊邏輯」而設計出來的。有興趣的話可以參考[這篇論文](http://mopl.as.ntu.edu.tw/web/ASJ/40/40-1-4.pdf)。\n",
    "\n",
    "### **在這個 Notebook 嘗試想要做到的事情是，透過機器學習的方式做到預報。**\n",
    "目標取得的(歷史/即時)資料，包含板橋的**探空資料**以及板橋的**地面觀測資料**。\n",
    "* 板橋探空資料取得點，[這裡](http://weather.uwyo.edu/upperair/sounding.html)。\n",
    " * 目前 板橋測站(58968) 資料有到 2019 年，2020 似乎就沒有了..\n",
    " * 無關的歷史: 這是大二的時候，王國英老師在程繪課提供給我們的資料來源。那時候我們使用 Fortran + [NCAR Graphics](http://ngwww.ucar.edu/) 繪圖 ^_^。 \n",
    "* 板橋地面觀測資料取得點，[這裡](https://e-service.cwb.gov.tw/HistoryDataQuery/index.jsp)。\n",
    " * 使用其 **日報表**。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ayuaBEhWQBKB"
   },
   "source": [
    "# **2. 資料取得**\n",
    "* 探空資料: 利用 pandas read_csv 爬資料，parse 出目標資訊後，再依照日期命名儲存成一個csv檔。\n",
    "* 地面測站資料: 在 Github 上找到專門爬觀測資料查詢系統的 project，直接clone下來做使用，點[此連結](https://github.com/s3131212/CWB-Observation-Crawler)，以了解更多。這個人真的很厲害!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iRcEHxCwTrL5"
   },
   "source": [
    "### **CODE01: 取得探空資料**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ru4-q4VuUSbO"
   },
   "outputs": [],
   "source": [
    "import pandas as pd # 會用 pandas 爬資料\n",
    "import time # 擔心爬蟲爬的太頻繁，被網站封鎖，但好像不管多頻繁都沒有被鎖。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IpT3wQ58UlLx"
   },
   "outputs": [],
   "source": [
    "# input YEAR, MONTH, DAY 。觀察 uwyo sounding data 網址構成，發現其實會變動的只有 YEAR, MONTH, DAY，所以它們三個就做為 input 參數\n",
    "# output: data, base_url, boolean， 其中的 boolean 會告訴我們目標網址有沒有該資料，如果是 False 那就跳過這天，去爬下一天。\n",
    "\n",
    "def get_station_data(YEAR, MONTH, DAY):\n",
    "    time.sleep(0.1) # 這邊可以控制爬蟲的頻率\n",
    "    base_url = f\"http://weather.uwyo.edu/cgi-bin/sounding?region=naconf&TYPE=TEXT%3ALIST&YEAR={YEAR}&MONTH={MONTH}&FROM={DAY}00&TO={DAY}00&STNM=58968\"\n",
    "    print(base_url)\n",
    "    raw_data = pd.read_csv(base_url)\n",
    "    try:\n",
    "        data = raw_data[\"<HTML>\"] # 可以看看 raw_data 這個 dataframe 的結構，就知道為何這邊是使用[\"<HTML>\"]了\n",
    "        return data, base_url, True\n",
    "    except:\n",
    "        print(f\"[SYSTEM] {YEAR}{MONTH}{DAY} No Record\")\n",
    "        print(base_url)\n",
    "        data = None\n",
    "        return data, base_url, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VqqLyi_vVs7A"
   },
   "outputs": [],
   "source": [
    "# 取得 data 之後，要決定擷取資料的起始位置，在這邊，我定義開始位置是從 1000 hPa。\n",
    "# input: line (data 中一行又一行的資訊), i (data的第幾行)\n",
    "# output: boolean, i\n",
    "def detect_start_line(line, i):\n",
    "    x = line.split()\n",
    "    if x[0] == \"1000.0\": \n",
    "        return True, i\n",
    "    else:\n",
    "        return False, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JJ5C1iC0WfUU"
   },
   "outputs": [],
   "source": [
    "# 跟上面類似，取得 data 之後，要決定擷取資料的結束位置，在這邊，我定義結束位置是在 300 hPa。\n",
    "# input: line (data 中一行又一行的資訊), i (data的第幾行)\n",
    "# output: 回傳 boolean, i\n",
    "def detect_final_line(line, i):\n",
    "    x = line.split()\n",
    "    if x[0] == \"300.0\":\n",
    "        return True, i+1 # 這邊回傳 i+1 是因為...\n",
    "    else:\n",
    "        return False, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_i4P2d_CW_a4"
   },
   "outputs": [],
   "source": [
    "# 取得 data 之後，要確認每一行都有 11 個參數，有的話才將這筆資料納入。\n",
    "# input: line\n",
    "# output: boolean\n",
    "def test_complete(line):\n",
    "    x = line.split()\n",
    "    if len(x) == 11: return True\n",
    "    \n",
    "# 將 list 轉成 dataframe，因為 dataframe 可以直接變成 csv 檔儲存起來。\n",
    "# input: list\n",
    "# output: dataframe\n",
    "def list_to_dataframe(list):\n",
    "    return pd.DataFrame(list)\n",
    "\n",
    "# 先測試一下 dataframe 的 size 是不是 7 x 11 ，\"7\"是來自於 1000 hPa 到 300 hPa 預計共有 7 層；\"11\"是來自於 每一層高度涵蓋了 11個參數\n",
    "# input: dataframe，YEAR, MONTH, DAY\n",
    "# output: 沒有 output\n",
    "def test_dataframe_and_save(dataframe, YEAR, MONTH, DAY):\n",
    "    if dataframe_data.shape == (7,11):\n",
    "        dataframe_data.to_csv(f\"./sounding_data/{YEAR}/{YEAR}-{MONTH}-{DAY}.csv\")\n",
    "    else:\n",
    "        print(f\"[SYSTEM] {YEAR}{MONTH}{DAY} Incomplete Data\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IFGr54EpXqKa"
   },
   "outputs": [],
   "source": [
    "# 決定下載的資料區間，這邊我先下載 2015~2018年的5~10月的資訊，等等會拿一部分的資料當作 training dataset，一部分的資料當作 test dataset。\n",
    "YEARS = [2015,2016,2017,2018]\n",
    "MONTHS= [\"05\",\"06\",\"07\",\"08\",\"09\",\"10\"]\n",
    "# 小月: 六月、九月\n",
    "DAY_30= [\"01\",\"02\",\"03\",\"04\",\"05\",\"06\",\"07\",\"08\",\"09\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\"]\n",
    "# 大月: 五月、七月、八月、十月\n",
    "DAY_31= [\"01\",\"02\",\"03\",\"04\",\"05\",\"06\",\"07\",\"08\",\"09\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eF9B4i7rcaMW"
   },
   "source": [
    "因為接下來會牽涉到檔案的儲存，在google colab會需要先做一些設定，才能成功執行下面的code，如果是用自己本地端的電腦，那就只要在對的位置建立一個叫做data的資料夾，就可以執行了。\n",
    "\n",
    "所以下面這一格是使用 google colab 的人限定的。使用本地端 jupyter notebook 的話直接跳過沒有問題。建議可以直接到 github 看看專案的結構。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "id": "bdY5RIvTcweB",
    "outputId": "ebcc035b-5a29-4941-9da5-d3ac339e5817"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "mkdir: cannot create directory ‘sounding_data’: File exists\n"
     ]
    }
   ],
   "source": [
    "# 點擊下方網址，選擇要使用到的 goole 帳戶，然後將對應的 key 填入 textbox 中，\n",
    "# ! mkdir \"sounding_data\" 會在左側 content/ 目錄底下建立一個 sounding_data/ 目錄，等等爬下來的資料都會放在那邊。\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")\n",
    "! mkdir \"sounding_data\"\n",
    "! mkdir \"sounding_data/2015\"\n",
    "! mkdir \"sounding_data/2016\"\n",
    "! mkdir \"sounding_data/2017\"\n",
    "! mkdir \"sounding_data/2018\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q00JWqt9YQVD"
   },
   "outputs": [],
   "source": [
    "# 下面的程式執行後，就會按照我們選擇的時間下去做爬蟲，這裡直接用 loop 跑 [2015,2016,2017,2018]，執行一次就可以把四年的資料都爬下來了。\n",
    "# 大概會花 10 分鐘把四年的資料載完\n",
    "\n",
    "for YEAR in YEARS:\n",
    "  for MONTH in MONTHS:\n",
    "    if MONTH in [\"05\",\"07\",\"08\",\"10\"]: # 大月\n",
    "        for DAY in DAY_31:\n",
    "            flag = True\n",
    "            data, url, flag = get_station_data(YEAR,MONTH,DAY)\n",
    "            if flag == False: continue # 可以回頭看看 def get_station_data\n",
    "        \n",
    "            # 找到資料的第一行: i.e. hPa為 1000.0\n",
    "            for i in range(len(data)):\n",
    "                flag = False\n",
    "                line = data[i]\n",
    "                flag, START_LINE = detect_start_line(line, i)\n",
    "                if flag != False: break\n",
    "\n",
    "            # 找到資料的最後一行: i.e. hPa為 300.0\n",
    "            for i in range(len(data)):\n",
    "                flag = False\n",
    "                line = data[i]\n",
    "                flag, FINAL_LINE = detect_final_line(line, i)\n",
    "                if flag != False: break\n",
    "            \n",
    "            # 用來儲存資料的容器，一天會有一筆，所以每一天都要清空一次   \n",
    "            sounding_data_list = []\n",
    "        \n",
    "            for i in range(START_LINE, FINAL_LINE):\n",
    "                line = data[i]\n",
    "                if test_complete(line): sounding_data_list.append(line.split())\n",
    "            \n",
    "            # 將資料轉成　dataframe 的形式\n",
    "            dataframe_data = list_to_dataframe(sounding_data_list)\n",
    "            test_dataframe_and_save(dataframe_data, YEAR, MONTH, DAY)\n",
    "            \n",
    "    else: # 小月(6月和9月)，下面跟上面大同小異，通常會建議模組化，比較乾淨，不要學我XD\n",
    "        for DAY in DAY_30:\n",
    "            flag == True\n",
    "            data, url, flag = get_station_data(YEAR,MONTH,DAY)\n",
    "            if flag == False: continue\n",
    "        \n",
    "            # 找到資料的第一行: i.e. hPa為 1000.0\n",
    "            for i in range(len(data)):\n",
    "                flag = False\n",
    "                line = data[i]\n",
    "                flag, START_LINE = detect_start_line(line, i)\n",
    "                if flag != False: break\n",
    "\n",
    "            # 找到資料的最後一行: i.e. hPa為 300.0\n",
    "            for i in range(len(data)):\n",
    "                flag = False\n",
    "                line = data[i]\n",
    "                flag, FINAL_LINE = detect_final_line(line, i)\n",
    "                if flag != False: break\n",
    "\n",
    "            # 用來儲存資料的容器，一天會有一筆，所以每一天都要清空一次   \n",
    "            sounding_data_list = []\n",
    "        \n",
    "            for i in range(START_LINE, FINAL_LINE):\n",
    "                line = data[i]\n",
    "                if test_complete(line): sounding_data_list.append(line.split())\n",
    "\n",
    "            # 將資料轉成　dataframe 的形式\n",
    "            dataframe_data = list_to_dataframe(sounding_data_list)\n",
    "            test_dataframe_and_save(dataframe_data, YEAR, MONTH, DAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zl1GmY9ve_Sb"
   },
   "source": [
    "### 統計 sounding data\n",
    "**以下是運用工人智慧(笑)，所統計出來的結果。**\n",
    "\n",
    "#### sounding data 有問題的資料統計結果\n",
    "* 2018 共 05 筆: incomplete data 有2筆、no record 有 3筆\n",
    "* 2017 共 34 筆: incomplete data 有2筆、no record 有32筆 (整個5月都沒資料)\n",
    "* 2016 共 28 筆: incomplete data 有2筆、no record 有26筆\n",
    "* 2015 共 13 筆: incomplete data 有6筆、no record 有 7筆\n",
    "\n",
    "#### sounding data OKAY正常的資料總數\n",
    "Note: 5月到 10月共有184天，所以理想每年會有184筆資料。\n",
    "* 2018 共 179\n",
    "* 2017 共 150\n",
    "* 2016 共 156\n",
    "* 2015 共 171\n",
    "\n",
    "**太棒了，有問題的資料總數，加上，沒有問題的資料總數是 184。針對爬取 sounding data 到這邊告一段落。**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WPcqCMxzhXso"
   },
   "source": [
    "## CODE 02: 取得地面測站資料\n",
    "這邊就可以 git clone 高手的專案，然後稍微調整一下參數就可以用了。\n",
    "<br>\n",
    "**ref: https://github.com/s3131212/CWB-Observation-Crawler**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "-ylrmSomhWr0",
    "outputId": "eebcee85-a32f-4613-fbb2-9909ba23e575"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'CWB-Observation-Crawler' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "# 執行完這一行之後就可以看到 content/ 目錄底下多了一個 CWB-Observation-Crawler/ 的目錄\n",
    "! git clone https://github.com/s3131212/CWB-Observation-Crawler.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Qy7gEveiZNE"
   },
   "source": [
    "## 修改程式碼\n",
    "\n",
    "## **第一步驟: 打開程式檔**\n",
    "\n",
    "開啟 CWB-Observation-Crawler/ climate_crawler.py，我們要稍微修改一下程式最上面的部分。\n",
    "\n",
    "## **第二步驟: 調整測站編號**\n",
    "板橋地面測站的編號是 466880，所以將原本的第三行\n",
    "```\n",
    "twStationList = [\"466910\", \"466920\", \"466930\", \"C0A980\", \"C0A990\", \"C0A9A0\", \"C0A9B0\", \"C0A9C0\", \"C0A9E0\", \"C0A9F0\", \"C0AC40\", \"C0AC70\", \"C0AC80\", \"C0AH40\", \"C0AH70\", \"C1A730\", \"C1AC50\"]\n",
    "```\n",
    "\n",
    "改成\n",
    "```\n",
    "twStationList = [\"466880\"]\n",
    "```\n",
    "\n",
    "## **第三步驟: 調整年份**\n",
    "原本的第5行是\n",
    "```\n",
    "yearList=['2017', '2018']\n",
    "```\n",
    "將它改為我們想要的年份，以現在的case而言，就是2015~2018\n",
    "```\n",
    "yearList=[\"2015\",\"2016\",\"2017\",\"2018\"]\n",
    "```\n",
    "## **第四步驟: 調整月份**\n",
    "原本的第7行是\n",
    "```\n",
    "monthSearch = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "```\n",
    "把它改成\n",
    "```\n",
    "monthSearch = [5, 6, 7, 8, 9, 10]\n",
    "```\n",
    "\n",
    "**Note: 都修正完之後，記得要 ctrl+s 儲存一下呦~**\n",
    "## **最後一步驟:執行程式**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "ItvffDRniYZo",
    "outputId": "d73feed1-69e1-4ad9-ec6b-9f462558bbda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.6.9\n"
     ]
    }
   ],
   "source": [
    "# 原則上 colab 會幫我們把 python 裝好，所以可以直接用，不過保險起見，我們還是透過呼叫它的版本來確定它有真的存在吧。\n",
    "! python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "49290xBSk3ry"
   },
   "outputs": [],
   "source": [
    "# 這邊會花一點時間去爬資料，爬完的資料會被存在 content/data/466880 裡面\n",
    "! python CWB-Observation-Crawler/climate_crawler.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fa-9HBIkmuDi"
   },
   "source": [
    "# **3. 合併資料**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QY8cv1w4lt-e"
   },
   "source": [
    "## CODE 03: 合併兩個資料\n",
    "目前兩個資料目錄路徑分別是...\n",
    "\n",
    "### sounding data 依年份目錄路徑做區分\n",
    "**注意: 如果剛剛在 CODE01 只有順著執行下來，那就只會有原本預設的 2018的資料夾喔，可以改成 loop 的方式，也可以手動4次。**\n",
    "* content/ sounding_data/ 2015/\n",
    "* content/ sounding_data/ 2016/\n",
    "* content/ sounding_data/ 2017/\n",
    "* content/ sounding_data/ 2018/\n",
    "\n",
    "### station data 依年份目錄路徑做區分\n",
    "* content/ data/ 466880/ 2015/\n",
    "* content/ data/ 466880/ 2016/\n",
    "* content/ data/ 466880/ 2017/\n",
    "* content/ data/ 466880/ 2018/\n",
    "\n",
    "**有了這樣子的結構之後，待會就可以依照年份(2015,2016,2017,2018)做loop的操作了**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z81y4Gqsm3nk"
   },
   "outputs": [],
   "source": [
    "import os # 待會兒會需要 os.listdir() 列出檔案目錄下的檔案\n",
    "import pandas as pd # pandas 是拼接資料的好幫手"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wxKJJRfiqZWh"
   },
   "outputs": [],
   "source": [
    "# 檢查每一天的資料都有 117 個參數，117個分別來自 sounding data 的 77 個，和 station data 的 40 個。\n",
    "# station data 的 40 個參數分別來自，8 a.m., 9 a.m., 10 a.m. 11 a.m.的時間點，每個時間點我一共挑選了10個參數，下面就會看到哪10個。\n",
    "# input: small_list (包含每一天的探空和地面資料), file_name (單純用來記錄發生問題的檔案名稱，見 elif block)\n",
    "# output: boolean\n",
    "def check_complete(small_list, file_name):\n",
    "    if len(small_list) == 117: return True\n",
    "    elif len(small_list) != 117:\n",
    "        print(len(small_list))\n",
    "        print(f\"[SYSTEM] {file_name} Small List Incomplete Data\")\n",
    "        return False\n",
    "\n",
    "# 決定每一天資料 label 的地方。\n",
    "# 目前會把 Label 設為 True 的條件是: \n",
    "#    1. 早上8~12點累積雨量小於 2mm，且\n",
    "#    2. 下午12~18點累積雨量大於 5mm\n",
    "# 這樣我就把它設為 Ture，其他不在這個條件內的，全部都設為 False\n",
    "# 我知道目前的判斷的方式確實待調整，但就在下一版做調整吧!\n",
    "def decide_label(data,file_name):\n",
    "    morning_sum = 0.0\n",
    "    for num in list(data[8:12]):\n",
    "        if num == \"T\": num = \"0.1\" # 地面測站會出現 \"T\" ，表示是毛毛雨\n",
    "        num = float(num)\n",
    "        morning_sum = morning_sum + num\n",
    "\n",
    "    afternoon_sum = 0.0\n",
    "    for num in list(data[12:18]):\n",
    "        if num == \"T\": num = \"0.1\"\n",
    "        num = float(num)\n",
    "        afternoon_sum = afternoon_sum + num\n",
    "\n",
    "    if morning_sum < 2.0 and afternoon_sum > 5.0:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "2z8U1jQfybwD",
    "outputId": "98391ad8-20ed-495f-8182-f57c3a88c70b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘model_data’: File exists\n"
     ]
    }
   ],
   "source": [
    "# 下面的 code 會把資料合併，並儲存在這個 folder 裡面，\n",
    "! mkdir \"model_data\" # 目錄路徑再 content/model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "id": "4oskxZE_x9Zv",
    "outputId": "74ef8054-2af6-4a75-dec9-3aff798c511e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SYSTEM] Total # of Data 656\n",
      "[SYSTEM] 檔案儲存完畢! 儲存於 content/model_data/all_data_with_label.csv\n"
     ]
    }
   ],
   "source": [
    "# 建立一個空的 list 容器\n",
    "data_list = []\n",
    "\n",
    "# loop 這四年的資料夾\n",
    "for YEAR in [2015,2016,2017,2018]:\n",
    "\n",
    "    # 設定 folder path\n",
    "    PATH_TO_STATION_DATA = f\"data/466880/{YEAR}/\"\n",
    "    PATH_TO_SOUNDING_DATA= f\"sounding_data/{YEAR}/\"\n",
    "\n",
    "    # 這裡是針對 sounding data 做 loop 是因為 sounding data 的資料有漏，station data 的資料沒有漏，\n",
    "    # 所以為了確保資料是完整的(有探空也有地面)，我們在這裡就會以 sounding data 作為loop的對象。\n",
    "    for file_name in os.listdir(PATH_TO_SOUNDING_DATA):\n",
    "        \n",
    "        # 每一天資料的容器\n",
    "        small_list = []\n",
    "        \n",
    "        # Station Data 的部分(共40個參數)\n",
    "        station_data = pd.read_csv(PATH_TO_STATION_DATA + file_name)\n",
    "        # 每個時間點(8 a.m. ~ 12 a.m.)，都會去索取以下這10個參數\n",
    "        target_station_data = station_data[8:12][{\"測站氣壓\",\"氣溫\",\"相對溼度\",\"露點溫度\",\"風向\",\"風速\",\"最大陣風\",\"最大陣風風向\",\"日照時數\",\"全天空日射量\"}]\n",
    "        for key in [\"測站氣壓\",\"氣溫\",\"相對溼度\",\"露點溫度\",\"風向\",\"風速\",\"最大陣風\",\"最大陣風風向\",\"日照時數\",\"全天空日射量\"]:\n",
    "            for value in target_station_data[f\"{key}\"]: \n",
    "                small_list.append(value)\n",
    "        \n",
    "        ## 在這邊決定 station data 的 Label\n",
    "        label = decide_label(station_data[\"降水量\"], file_name)\n",
    "        \n",
    "        ## Sounding Data 的部分(共77個參數)\n",
    "        sounding_data = pd.read_csv(PATH_TO_SOUNDING_DATA+file_name)\n",
    "        target_sounding_data = sounding_data[0:][{\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\"}]\n",
    "        for key in [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\"]:\n",
    "            for value in target_sounding_data[f\"{key}\"]: \n",
    "                small_list.append(value)\n",
    "        \n",
    "        # 執行到這邊，表示每一天資料的容器都已經裝好來自 sounding 和 station 的 data 了。\n",
    "        # 檢查是否有完整的 117 筆資料，有的話再多加兩個參數: 檔名(file_name) 和 標籤(label)\n",
    "        if check_complete(small_list, file_name):\n",
    "            small_list.append(file_name)\n",
    "            small_list.append(label)\n",
    "\n",
    "            # 將完整的 small_list append 進 data_list 當中\n",
    "            data_list.append(small_list)\n",
    "        else:  # 如果沒有完整的 117 筆資料，那就跳過這個 iterarion\n",
    "            continue\n",
    "\n",
    "# 執行到這邊，表示已經把 4年 的資料都放進 data_list 裡面了\n",
    "print(f\"[SYSTEM] Total # of Data {len(data_list)}\") \n",
    "\n",
    "# 把二維的 data_list 轉成 dataframe\n",
    "all_data = pd.DataFrame(data_list)\n",
    "\n",
    "# 把 dataframe 存成一個csv檔\n",
    "all_data.to_csv(\"model_data/all_data_with_label.csv\")\n",
    "print(\"[SYSTEM] 檔案儲存完畢! 儲存於 content/model_data/all_data_with_label.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yyu1v_sP5fXu"
   },
   "source": [
    "# **4. 機器學習**\n",
    "這邊用到 Scikit learn 最基本的一些API。這邊目前沒有花特別多的時間鑽研，想要知道更多 Scikit learn 關於如何使用的內容，請直接參考 [Scikit Learn Documentation](https://scikit-learn.org/stable/)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cHgzt7Tz-Fe1"
   },
   "source": [
    "## CODE 04: 用 scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 412
    },
    "id": "jq0QwCWv5opA",
    "outputId": "93b1c329-94d5-43af-bd85-a96233a73f1e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>...</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1006.0</td>\n",
       "      <td>1005.9</td>\n",
       "      <td>1005.9</td>\n",
       "      <td>1005.4</td>\n",
       "      <td>29.3</td>\n",
       "      <td>31.3</td>\n",
       "      <td>31.9</td>\n",
       "      <td>33.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>20.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>200.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.2</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>11.4</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.77</td>\n",
       "      <td>2.07</td>\n",
       "      <td>2.90</td>\n",
       "      <td>...</td>\n",
       "      <td>2.76</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.79</td>\n",
       "      <td>210</td>\n",
       "      <td>245</td>\n",
       "      <td>245</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>265</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>29</td>\n",
       "      <td>23</td>\n",
       "      <td>29</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>300.4</td>\n",
       "      <td>303.6</td>\n",
       "      <td>308.6</td>\n",
       "      <td>313.8</td>\n",
       "      <td>327.7</td>\n",
       "      <td>337.9</td>\n",
       "      <td>347.1</td>\n",
       "      <td>342.2</td>\n",
       "      <td>338.3</td>\n",
       "      <td>330.7</td>\n",
       "      <td>344.6</td>\n",
       "      <td>337.4</td>\n",
       "      <td>343.5</td>\n",
       "      <td>350.2</td>\n",
       "      <td>302.9</td>\n",
       "      <td>305.8</td>\n",
       "      <td>309.9</td>\n",
       "      <td>315.6</td>\n",
       "      <td>328.3</td>\n",
       "      <td>338.2</td>\n",
       "      <td>347.2</td>\n",
       "      <td>2015-05-19.csv</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1016.4</td>\n",
       "      <td>1016.4</td>\n",
       "      <td>1015.8</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>27.4</td>\n",
       "      <td>29.1</td>\n",
       "      <td>30.5</td>\n",
       "      <td>32.5</td>\n",
       "      <td>72.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.1</td>\n",
       "      <td>22.5</td>\n",
       "      <td>22.4</td>\n",
       "      <td>220.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.42</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.71</td>\n",
       "      <td>115</td>\n",
       "      <td>145</td>\n",
       "      <td>240</td>\n",
       "      <td>245</td>\n",
       "      <td>130</td>\n",
       "      <td>15</td>\n",
       "      <td>315</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>298.9</td>\n",
       "      <td>302.2</td>\n",
       "      <td>306.0</td>\n",
       "      <td>314.6</td>\n",
       "      <td>328.2</td>\n",
       "      <td>335.5</td>\n",
       "      <td>343.1</td>\n",
       "      <td>346.4</td>\n",
       "      <td>344.5</td>\n",
       "      <td>347.2</td>\n",
       "      <td>327.9</td>\n",
       "      <td>330.7</td>\n",
       "      <td>337.2</td>\n",
       "      <td>345.9</td>\n",
       "      <td>301.9</td>\n",
       "      <td>304.8</td>\n",
       "      <td>308.5</td>\n",
       "      <td>315.4</td>\n",
       "      <td>328.4</td>\n",
       "      <td>335.6</td>\n",
       "      <td>343.3</td>\n",
       "      <td>2015-10-05.csv</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1006.9</td>\n",
       "      <td>1007.1</td>\n",
       "      <td>1007.1</td>\n",
       "      <td>1006.8</td>\n",
       "      <td>29.2</td>\n",
       "      <td>30.7</td>\n",
       "      <td>32.1</td>\n",
       "      <td>33.3</td>\n",
       "      <td>76.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>24.6</td>\n",
       "      <td>25.0</td>\n",
       "      <td>24.4</td>\n",
       "      <td>24.3</td>\n",
       "      <td>250.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.7</td>\n",
       "      <td>240.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.57</td>\n",
       "      <td>2.43</td>\n",
       "      <td>3.09</td>\n",
       "      <td>...</td>\n",
       "      <td>3.86</td>\n",
       "      <td>2.52</td>\n",
       "      <td>0.88</td>\n",
       "      <td>285</td>\n",
       "      <td>205</td>\n",
       "      <td>115</td>\n",
       "      <td>215</td>\n",
       "      <td>240</td>\n",
       "      <td>270</td>\n",
       "      <td>345</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>300.1</td>\n",
       "      <td>304.2</td>\n",
       "      <td>306.4</td>\n",
       "      <td>316.9</td>\n",
       "      <td>329.2</td>\n",
       "      <td>337.6</td>\n",
       "      <td>345.4</td>\n",
       "      <td>353.6</td>\n",
       "      <td>350.9</td>\n",
       "      <td>349.6</td>\n",
       "      <td>345.7</td>\n",
       "      <td>342.5</td>\n",
       "      <td>346.8</td>\n",
       "      <td>348.9</td>\n",
       "      <td>303.4</td>\n",
       "      <td>307.1</td>\n",
       "      <td>309.1</td>\n",
       "      <td>318.6</td>\n",
       "      <td>330.0</td>\n",
       "      <td>338.1</td>\n",
       "      <td>345.6</td>\n",
       "      <td>2015-06-24.csv</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1009.2</td>\n",
       "      <td>1009.1</td>\n",
       "      <td>1009.1</td>\n",
       "      <td>1008.9</td>\n",
       "      <td>29.0</td>\n",
       "      <td>30.9</td>\n",
       "      <td>31.5</td>\n",
       "      <td>32.6</td>\n",
       "      <td>73.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>23.7</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.1</td>\n",
       "      <td>24.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>40.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.34</td>\n",
       "      <td>2.17</td>\n",
       "      <td>1.59</td>\n",
       "      <td>1.65</td>\n",
       "      <td>...</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.42</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0</td>\n",
       "      <td>245</td>\n",
       "      <td>295</td>\n",
       "      <td>210</td>\n",
       "      <td>215</td>\n",
       "      <td>245</td>\n",
       "      <td>305</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>299.4</td>\n",
       "      <td>302.8</td>\n",
       "      <td>307.3</td>\n",
       "      <td>315.3</td>\n",
       "      <td>328.7</td>\n",
       "      <td>335.8</td>\n",
       "      <td>343.7</td>\n",
       "      <td>350.7</td>\n",
       "      <td>350.7</td>\n",
       "      <td>346.6</td>\n",
       "      <td>338.0</td>\n",
       "      <td>335.7</td>\n",
       "      <td>341.1</td>\n",
       "      <td>346.2</td>\n",
       "      <td>302.5</td>\n",
       "      <td>305.7</td>\n",
       "      <td>309.7</td>\n",
       "      <td>316.6</td>\n",
       "      <td>329.1</td>\n",
       "      <td>336.1</td>\n",
       "      <td>343.8</td>\n",
       "      <td>2015-06-15.csv</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1005.0</td>\n",
       "      <td>1004.8</td>\n",
       "      <td>1004.4</td>\n",
       "      <td>1004.0</td>\n",
       "      <td>28.7</td>\n",
       "      <td>30.2</td>\n",
       "      <td>31.9</td>\n",
       "      <td>32.6</td>\n",
       "      <td>68.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>22.2</td>\n",
       "      <td>23.3</td>\n",
       "      <td>22.8</td>\n",
       "      <td>22.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.3</td>\n",
       "      <td>7.5</td>\n",
       "      <td>8.6</td>\n",
       "      <td>80.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.27</td>\n",
       "      <td>1.93</td>\n",
       "      <td>2.70</td>\n",
       "      <td>3.44</td>\n",
       "      <td>...</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.19</td>\n",
       "      <td>165</td>\n",
       "      <td>80</td>\n",
       "      <td>75</td>\n",
       "      <td>90</td>\n",
       "      <td>75</td>\n",
       "      <td>50</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>298.6</td>\n",
       "      <td>303.0</td>\n",
       "      <td>306.2</td>\n",
       "      <td>315.1</td>\n",
       "      <td>328.9</td>\n",
       "      <td>337.4</td>\n",
       "      <td>344.5</td>\n",
       "      <td>343.4</td>\n",
       "      <td>343.4</td>\n",
       "      <td>340.6</td>\n",
       "      <td>339.1</td>\n",
       "      <td>330.3</td>\n",
       "      <td>338.0</td>\n",
       "      <td>345.3</td>\n",
       "      <td>301.3</td>\n",
       "      <td>305.5</td>\n",
       "      <td>308.3</td>\n",
       "      <td>316.5</td>\n",
       "      <td>329.0</td>\n",
       "      <td>337.4</td>\n",
       "      <td>344.6</td>\n",
       "      <td>2015-08-06.csv</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 119 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0       1       2       3  ...    115    116             117    118\n",
       "0  1006.0  1005.9  1005.9  1005.4  ...  338.2  347.2  2015-05-19.csv  False\n",
       "1  1016.4  1016.4  1015.8  1015.0  ...  335.6  343.3  2015-10-05.csv  False\n",
       "2  1006.9  1007.1  1007.1  1006.8  ...  338.1  345.6  2015-06-24.csv   True\n",
       "3  1009.2  1009.1  1009.1  1008.9  ...  336.1  343.8  2015-06-15.csv  False\n",
       "4  1005.0  1004.8  1004.4  1004.0  ...  337.4  344.6  2015-08-06.csv  False\n",
       "\n",
       "[5 rows x 119 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd # 一樣也是使用 pandas 去 read_csv\n",
    "df = pd.read_csv(\"model_data/all_data_with_label.csv\", index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1clJD1v_7kWW"
   },
   "outputs": [],
   "source": [
    "import sklearn # google colab 預設也有 sickit learn\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "id": "KB8MTdTB7ycV",
    "outputId": "c965f3cc-f42f-4af0-f5ff-4589570c8369"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=50.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 92,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 將656筆資料洗牌一下\n",
    "df = sklearn.utils.shuffle(df)\n",
    "\n",
    "# 將 NaN 的資料用平均數代替\n",
    "df=df.fillna(df.mean())\n",
    "\n",
    "# 設計我們的X，把118的 Label 和 117的檔名 拿掉\n",
    "X = df.drop({\"118\",\"117\"}, axis=1).values \n",
    "\n",
    "# 設計我們的Y，把118的 Label 獨立出來，同時把 True, False 映射(map)給 1, 0。\n",
    "df[\"118\"] = df[\"118\"].map({True:1, False:0})\n",
    "y = df[\"118\"].values\n",
    "\n",
    "# 用來算分數的 test_dataset size 設為 100\n",
    "test_size = 100\n",
    "\n",
    "# 將資料切成 訓練集(training set) 和 測試集(testing set)\n",
    "X_train = X[:-test_size]\n",
    "y_train = y[:-test_size]\n",
    "X_test = X[-test_size:]\n",
    "y_test = y[-test_size:]\n",
    "\n",
    "# clf 等於 classifier，利用 svm 的 library 建立一個 classifier\n",
    "clf = svm.SVC(gamma=0.001, C=50.)\n",
    "\n",
    "# 拿 training dataset 訓練 clf\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "AA9baWtZ9GaB",
    "outputId": "f4a819b9-8559-414d-f332-fc17aa060d1a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 93,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 拿 testing datast 來評分\n",
    "clf.score(X_test, y_test)\n",
    "\n",
    "# 還有很多可以用來評分的 metrices，就參考一下 scikit learn documentation 吧。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R7-PqUeB-PgX"
   },
   "source": [
    "# **5. 未來目標**\n",
    "* **調整 決定資料 Label 的方式。**\n",
    "* **增加 Dataset 的時間涵蓋範圍(ex: 從2010開始收集資料)**\n",
    "* **在訓練前做到 [EDA](https://towardsdatascience.com/exploratory-data-analysis-8fc1cb20fd15)**\n",
    "* **用 sklearn 其他機器學習的方式做做看 (ex: Tree models)**\n",
    "* **用 deep learning 的方式做做看。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vvD6EHa7JaEn"
   },
   "source": [
    "# **6. 參考連結**\n",
    "* [NCDR 天氣氣候監測 - 大台北午後對流檢查表](https://watch.ncdr.nat.gov.tw/watch_ntp)\n",
    "* [弱綜觀環境下台灣午後對流特徵及其客觀預報](http://mopl.as.ntu.edu.tw/web/ASJ/40/40-1-4.pdf)\n",
    "* [UWYO Sounding Data](http://weather.uwyo.edu/upperair/sounding.html)\n",
    "* [NCAR Graphics 官網](http://ngwww.ucar.edu/)\n",
    "* [觀測資料查詢系統](https://e-service.cwb.gov.tw/HistoryDataQuery/index.jsp)\n",
    "* [Github CWB-Observation-Crawler Project](https://github.com/s3131212/CWB-Observation-Crawler)\n",
    "* [Scikit Learn Documentation](https://scikit-learn.org/stable/)\n",
    "* [EDA 介紹: What is Exploratory Data Analysis?](https://towardsdatascience.com/exploratory-data-analysis-8fc1cb20fd15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HJ3EqtwGBgqR"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "臺北午後雷陣雨預報系統",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
